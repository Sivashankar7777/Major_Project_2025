{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sivashankar7777/Major_Project_2025/blob/main/Table_using_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzyX0VkWX9Y0",
        "outputId": "916cc64e-06d1-4a17-a196-9e4e36f752c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ultralyticsplus\n",
            "  Downloading ultralyticsplus-0.1.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from ultralyticsplus) (0.28.1)\n",
            "Collecting fire (from ultralyticsplus)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ultralytics<8.1.0,>=8.0.225 (from ultralyticsplus)\n",
            "  Downloading ultralytics-8.0.239-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting sahi<0.12.0,>=0.11.11 (from ultralyticsplus)\n",
            "  Downloading sahi-0.11.20-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting roboflow>=0.2.32 (from ultralyticsplus)\n",
            "  Downloading roboflow-1.1.53-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting protobuf<3.21,>=3.20 (from ultralyticsplus)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.12.0->ultralyticsplus) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow>=0.2.32->ultralyticsplus)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (3.10.0)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow>=0.2.32->ultralyticsplus)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting python-dotenv (from roboflow>=0.2.32->ultralyticsplus)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (2.3.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.32->ultralyticsplus) (1.0.0)\n",
            "Collecting filetype (from roboflow>=0.2.32->ultralyticsplus)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi<0.12.0,>=0.11.11->ultralyticsplus) (2.0.7)\n",
            "Collecting pybboxes==0.1.6 (from sahi<0.12.0,>=0.11.11->ultralyticsplus)\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting terminaltables (from sahi<0.12.0,>=0.11.11->ultralyticsplus)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi<0.12.0,>=0.11.11->ultralyticsplus) (8.1.8)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (0.20.1+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (0.13.2)\n",
            "Collecting hub-sdk>=0.0.2 (from ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading hub_sdk-0.0.18-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->ultralyticsplus) (2.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow>=0.2.32->ultralyticsplus) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow>=0.2.32->ultralyticsplus) (4.55.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow>=0.2.32->ultralyticsplus) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.12.0->ultralyticsplus) (3.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics<8.1.0,>=8.0.225->ultralyticsplus) (3.0.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading ultralyticsplus-0.1.0-py3-none-any.whl (23 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.53-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sahi-0.11.20-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.0.239-py3-none-any.whl (699 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.1/699.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hub_sdk-0.0.18-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=4c989314493dd7c7406fc08653959f9e45c1dbe930c94be74c7a3557b9eff06d\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: filetype, terminaltables, python-dotenv, pytesseract, pybboxes, protobuf, opencv-python-headless, opencv-python, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, sahi, nvidia-cusolver-cu12, hub-sdk, roboflow, thop, ultralytics, ultralyticsplus\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 fire-0.7.0 hub-sdk-0.0.18 idna-3.7 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.10.0.84 opencv-python-headless-4.10.0.84 protobuf-3.20.3 pybboxes-0.1.6 pytesseract-0.3.13 python-dotenv-1.0.1 roboflow-1.1.53 sahi-0.11.20 terminaltables-3.1.10 thop-0.1.1.post2209072238 ultralytics-8.0.239 ultralyticsplus-0.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0c23e6b6ad0f4082828defd515b5e436",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (3,682 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy pandas pytesseract ultralyticsplus\n",
        "!apt install -y tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "355FMBn3Z3hX"
      },
      "outputs": [],
      "source": [
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "caf36135e9f644f0a5c45b12e6e5c181",
            "5b137633cac3466dbda43ce46abbe3ef"
          ]
        },
        "id": "AtZebN5GW10G",
        "outputId": "37f13ede-2dd9-4ef3-c598-217e079877d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 74.2MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py:634: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location=\"cpu\"), file  # load\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caf36135e9f644f0a5c45b12e6e5c181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/161 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b137633cac3466dbda43ce46abbe3ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "best.pt:   0%|          | 0.00/52.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py:634: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location=\"cpu\"), file  # load\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x448 1 bordered, 1940.4ms\n",
            "Speed: 23.8ms preprocess, 1940.4ms inference, 36.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "(641, 1063, 3)\n",
            "Combined Table 0:\n",
            "[' ', 'New version', 'Past Versions']\n",
            "['Restore fonts', 'Yes', 'No']\n",
            "['Restore font size', 'Yes', 'No']\n",
            "['Restore stamps', 'Yes', 'No']\n",
            "['Restore tables', 'Yes', 'No']\n",
            "['Restore pictures', 'Yes', 'No']\n",
            "['Preview the results', 'Yes', 'No']\n",
            "['Edit freely', 'Yes', 'No']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "from ultralyticsplus import YOLO\n",
        "from PIL import Image  # pillow\n",
        "import cv2\n",
        "import subprocess\n",
        "import csv\n",
        "import os\n",
        "\n",
        "\n",
        "# load The image\n",
        "image = cv2.imread('./test3.jpg')\n",
        "img = Image.fromarray(image)\n",
        "\n",
        "# load model\n",
        "model = YOLO('keremberke/yolov8m-table-extraction')\n",
        "\n",
        "# set model parameters\n",
        "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
        "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
        "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
        "model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
        "\n",
        "# perform inference\n",
        "results = model.predict(img)\n",
        "\n",
        "tables_vesul = []\n",
        "tables = []\n",
        "\n",
        "for i in range(len(results[0].boxes.data.numpy())):\n",
        "    x1, y1, x2, y2, _, _ = tuple(int(item) for item in results[0].boxes.data.numpy()[i])  # (96, 586, 947, 1286)\n",
        "    x2 += 10\n",
        "    y2 += 10\n",
        "    x1 -= 10\n",
        "    y1 -= 10\n",
        "\n",
        "    # cropping\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "    print(cropped_image.shape)\n",
        "    tables.append(cropped_image)\n",
        "    image_tab = Image.fromarray(cropped_image)\n",
        "    tables_vesul.append(image_tab)\n",
        "\n",
        "# Step 2 : Extracting data from the table\n",
        "\n",
        "\n",
        "def add_10_percent_padding(img):\n",
        "    image_height = img.shape[0]\n",
        "    padding = int(image_height * 0.1)\n",
        "    padded_img = cv2.copyMakeBorder(img, padding, padding, padding, padding, cv2.BORDER_CONSTANT,\n",
        "                                     value=[255, 255, 255])\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def img_Preprocessing(img):\n",
        "    # Grey-scaling\n",
        "    grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # converting it to binary image by Thresholding\n",
        "    thresholded_image = cv2.threshold(grayscale_image, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "    # Inverting\n",
        "    inverted_image = cv2.bitwise_not(thresholded_image)\n",
        "    return inverted_image\n",
        "\n",
        "\n",
        "def img_Preprocessing_ocr(img):\n",
        "    # Thresholding\n",
        "    thresholded_image = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "    # Inverting\n",
        "    # inverted_image = cv2.bitwise_not(thresholded_image)\n",
        "    return thresholded_image\n",
        "\n",
        "\n",
        "# Combining Vertical And Horizontal Lines\n",
        "def combine_eroded_images(img):\n",
        "    # Eroding Vertical Lines\n",
        "    hor = np.array([[1, 1, 1, 1, 1, 1]])\n",
        "    ver_erode_img = cv2.erode(img, hor, iterations=5)\n",
        "    ver_dilate_img = cv2.dilate(ver_erode_img, hor, iterations=10)\n",
        "    # Eroding Horizontal Lines\n",
        "    ver = np.array([[1], [1], [1], [1], [1], [1], [1]])\n",
        "    hor_erode_img = cv2.erode(img, ver, iterations=5)\n",
        "    hor_dilate_img = cv2.dilate(hor_erode_img, ver, iterations=10)\n",
        "    # Combining\n",
        "    combined_image = cv2.add(ver_dilate_img, hor_dilate_img)\n",
        "    # dilate combined_image to make lines thicker\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    combined_image_dilated = cv2.dilate(combined_image, kernel, iterations=5)\n",
        "    return combined_image_dilated\n",
        "\n",
        "\n",
        "# Removing The Lines\n",
        "def subtract_combined_and_dilated_image_from_original_image(processed_img, combined_image_dilated):\n",
        "    img_without_lines = cv2.subtract(processed_img, combined_image_dilated)\n",
        "    # remove noise with erode and dilate\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    image_without_lines_noise_removed = cv2.erode(img_without_lines, kernel)\n",
        "    image_without_lines_noise_removed = cv2.dilate(image_without_lines_noise_removed, kernel)\n",
        "    return image_without_lines_noise_removed\n",
        "\n",
        "\n",
        "# Finding The Blobs and Extracting The Text From Them\n",
        "\n",
        "# Use Dilation To Convert The Words Into Blobs\n",
        "def dilate_image(thresholded_image):\n",
        "    kernel_to_remove_gaps_between_words = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "                                                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "    dilated_image = cv2.dilate(thresholded_image, kernel_to_remove_gaps_between_words, iterations=5)\n",
        "    simple_kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated_image = cv2.dilate(dilated_image, simple_kernel, iterations=2)\n",
        "    return dilated_image\n",
        "\n",
        "\n",
        "# Find The Contours Of The Blobs\n",
        "def find_contours(dilated_image, original_image):\n",
        "    result = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = result[0]\n",
        "    # The code below is for visualization purposes only.\n",
        "    image_with_contours_drawn = original_image.copy()\n",
        "    cv2.drawContours(image_with_contours_drawn, contours, -1, (0, 255, 0), 3)\n",
        "    return contours, image_with_contours_drawn\n",
        "\n",
        "\n",
        "# Convert The Blobs Into Bounding Boxes\n",
        "def convert_contours_to_bounding_boxes(contours, original_image):\n",
        "    bounding_boxes = []\n",
        "    image_bounding_boxes = original_image.copy()\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append((x, y, w, h))\n",
        "        # The code below is for visualization purposes only.\n",
        "        image_bounding_boxes = cv2.rectangle(image_bounding_boxes, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
        "    return bounding_boxes, image_bounding_boxes\n",
        "\n",
        "\n",
        "# Sorting The Bounding Boxes By X And Y Coordinates To Make Rows And Columns\n",
        "def get_mean_height_of_bounding_boxes(bounding_boxes):\n",
        "    heights = []\n",
        "    for bounding_box in bounding_boxes:\n",
        "        x, y, w, h = bounding_box\n",
        "        heights.append(h)\n",
        "    return np.mean(heights)\n",
        "\n",
        "\n",
        "def sort_and_club_all_bounding_boxes_by_similar_y_coordinates_into_rows(bounding_boxes, mean_height):\n",
        "    # sort_bounding_boxes_by_y_coordinate\n",
        "    bounding_boxes = sorted(bounding_boxes, key=lambda x: x[1])\n",
        "    # club_all_bounding_boxes_by_similar_y_coordinates_into_rows\n",
        "    rows = []\n",
        "    half_of_mean_height = mean_height / 2\n",
        "    current_row = [bounding_boxes[0]]\n",
        "    for bounding_box in bounding_boxes[1:]:\n",
        "        current_bounding_box_y = bounding_box[1]\n",
        "        previous_bounding_box_y = current_row[-1][1]\n",
        "        distance_between_bounding_boxes = abs(current_bounding_box_y - previous_bounding_box_y)\n",
        "        if distance_between_bounding_boxes <= half_of_mean_height:\n",
        "            current_row.append(bounding_box)\n",
        "        else:\n",
        "            rows.append(current_row)\n",
        "            current_row = [bounding_box]\n",
        "    rows.append(current_row)\n",
        "\n",
        "    # sort_all_rows_by_x_coordinate\n",
        "    for row in rows:\n",
        "        row.sort(key=lambda x: x[0])\n",
        "    # Sort rows by the Y coordinate of the first box in each row\n",
        "    # rows.sort(key=lambda row: row[0][1])\n",
        "    return rows\n",
        "\n",
        "\n",
        "# Extracting The Text From The Bounding Boxes Using OCR\n",
        "def crop_each_bounding_box_and_ocr(rows, original_image):\n",
        "    table = []\n",
        "    current_row = []\n",
        "    image_number = 0\n",
        "    first_row = True  # Flag to indicate the first row\n",
        "\n",
        "    for row in rows:\n",
        "        if first_row:\n",
        "            # Add an empty string at the beginning of the first row\n",
        "            current_row.append(' ')  # Space character inside quotes\n",
        "            first_row = False  # Reset the flag\n",
        "\n",
        "        for bounding_box in row:\n",
        "            x, y, w, h = bounding_box\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "            image_without_lines_noise_removed = cv2.erode(add_10_percent_padding(original_image[y:y + h, x:x + w]),\n",
        "                                                           kernel)\n",
        "            cropped_image = cv2.dilate(image_without_lines_noise_removed, kernel)\n",
        "            image_slice_path = \"img_\" + str(image_number) + \".jpg\"\n",
        "            cv2.imwrite(image_slice_path, cropped_image)\n",
        "            results_from_ocr = tesseract_results(image_slice_path)\n",
        "            if not results_from_ocr:\n",
        "                current_row.append('\"\"')  # Add empty quotes if OCR result is empty\n",
        "            else:\n",
        "                current_row.append(results_from_ocr)\n",
        "            image_number += 1\n",
        "        table.append(current_row)\n",
        "        current_row = []\n",
        "    return table\n",
        "\n",
        "\n",
        "\n",
        "def tesseract_results(image_path):\n",
        "    # Construct the Tesseract OCR command\n",
        "    tesseract_command = (\n",
        "        'tesseract ' + image_path + ' - -l eng --oem 3 --psm 6 --dpi 300 '\n",
        "    )\n",
        "\n",
        "    # Run the Tesseract command using subprocess\n",
        "    output = subprocess.getoutput(tesseract_command)\n",
        "\n",
        "    # Strip any leading or trailing whitespace from the output\n",
        "    output = output.strip('|')\n",
        "    output = output.replace('\\n', ' ')\n",
        "    output = output.strip()\n",
        "    return output\n",
        "\n",
        "\n",
        "def generate_csv_file(input_table, i):\n",
        "    output_dir = \"./outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with open(f\"{output_dir}/Extracted_table_{i}.csv\", 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        for row in input_table:\n",
        "            csv_writer.writerow(row)\n",
        "\n",
        "    print(f\"Combined Table {i}:\")\n",
        "    for row in input_table:\n",
        "        print(row)\n",
        "\n",
        "\n",
        "for i, table in enumerate(tables):\n",
        "    image_with_padding = add_10_percent_padding(table)\n",
        "    processed_img = img_Preprocessing(image_with_padding)\n",
        "    combined_img = combine_eroded_images(processed_img)\n",
        "    img_without_lines = subtract_combined_and_dilated_image_from_original_image(processed_img, combined_img)\n",
        "    # Finding the cells & extracting the text using OCR\n",
        "    dilated_img = dilate_image(img_without_lines)\n",
        "    contours, image_with_contours_drawn = find_contours(dilated_img, image_with_padding)\n",
        "    bounding_boxes, img_bouding_boxes = convert_contours_to_bounding_boxes(contours, image_with_padding)\n",
        "    mean_height = get_mean_height_of_bounding_boxes(bounding_boxes)\n",
        "    sorted_rows = sort_and_club_all_bounding_boxes_by_similar_y_coordinates_into_rows(bounding_boxes, mean_height)\n",
        "    table = crop_each_bounding_box_and_ocr(sorted_rows, image_with_padding)\n",
        "    generate_csv_file(table, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "InBTh06gX7IF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}